{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2b67a8",
   "metadata": {},
   "source": [
    "## Pneumonia Detection and classification from Chest X-Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ce019",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a97b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea49c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8a6dd",
   "metadata": {},
   "source": [
    "#### Img training set generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1393b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator is working as basic python generator function\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/chest_xray/train',\n",
    "        # target_size=(-1, IMAGE_SIZE,IMAGE_SIZE, 1),\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d5f29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORMAL': 0, 'PNEUMONIA': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21066f96",
   "metadata": {},
   "source": [
    "#### available classes under training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e477a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NORMAL', 'PNEUMONIA']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ecaacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.16078432 0.16078432 0.16078432]\n",
      "  [0.16078432 0.16078432 0.16078432]\n",
      "  [0.16078432 0.16078432 0.16078432]\n",
      "  ...\n",
      "  [0.2631648  0.2631648  0.2631648 ]\n",
      "  [0.24068154 0.24068154 0.24068154]\n",
      "  [0.22681609 0.22681609 0.22681609]]\n",
      "\n",
      " [[0.15943131 0.15943131 0.15943131]\n",
      "  [0.15965271 0.15965271 0.15965271]\n",
      "  [0.15987411 0.15987411 0.15987411]\n",
      "  ...\n",
      "  [0.26117224 0.26117224 0.26117224]\n",
      "  [0.24001735 0.24001735 0.24001735]\n",
      "  [0.22593051 0.22593051 0.22593051]]\n",
      "\n",
      " [[0.15012896 0.15012896 0.15012896]\n",
      "  [0.15123594 0.15123594 0.15123594]\n",
      "  [0.1523429  0.1523429  0.1523429 ]\n",
      "  ...\n",
      "  [0.25917968 0.25917968 0.25917968]\n",
      "  [0.23935318 0.23935318 0.23935318]\n",
      "  [0.22504494 0.22504494 0.22504494]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for image_batch, label_batch in train_generator:\n",
    "    # print(label_batch)\n",
    "    print(image_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14cf4c",
   "metadata": {},
   "source": [
    "#### Img validation set generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a28625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'dataset/chest_xray/val',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179cfdd5",
   "metadata": {},
   "source": [
    "#### Img test set generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc7db4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/chest_xray/test',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beafd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.28188014 0.28188014 0.28188014]\n",
      "  [0.44212332 0.44212332 0.44212332]\n",
      "  [0.3913442  0.3913442  0.3913442 ]\n",
      "  ...\n",
      "  [0.26941854 0.26941854 0.26941854]\n",
      "  [0.27085558 0.27085558 0.27085558]\n",
      "  [0.2722926  0.2722926  0.2722926 ]]\n",
      "\n",
      " [[0.2752133  0.2752133  0.2752133 ]\n",
      "  [0.43886864 0.43886864 0.43886864]\n",
      "  [0.39353165 0.39353165 0.39353165]\n",
      "  ...\n",
      "  [0.25154254 0.25154254 0.25154254]\n",
      "  [0.25028512 0.25028512 0.25028512]\n",
      "  [0.2490277  0.2490277  0.2490277 ]]\n",
      "\n",
      " [[0.26928547 0.26928547 0.26928547]\n",
      "  [0.43132412 0.43132412 0.43132412]\n",
      "  [0.39586684 0.39586684 0.39586684]\n",
      "  ...\n",
      "  [0.23067422 0.23067422 0.23067422]\n",
      "  [0.22977605 0.22977605 0.22977605]\n",
      "  [0.2288779  0.2288779  0.2288779 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.18170224 0.18170224 0.18170224]\n",
      "  [0.15565227 0.15565227 0.15565227]\n",
      "  [0.08374965 0.08374965 0.08374965]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.18242076 0.18242076 0.18242076]\n",
      "  [0.1592449  0.1592449  0.1592449 ]\n",
      "  [0.08554596 0.08554596 0.08554596]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.18313928 0.18313928 0.18313928]\n",
      "  [0.16283752 0.16283752 0.16283752]\n",
      "  [0.08734227 0.08734227 0.08734227]]]\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in test_generator:\n",
    "    print(image_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f9e07",
   "metadata": {},
   "source": [
    "### Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f99a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5179456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size =(3,3), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2), strides=2, padding='same')\n",
    "\n",
    "model.add(Conv2D(64, kernel_size =(3,3), strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPool2D(2,2), strides=2, padding='same')\n",
    "\n",
    "model.add(Conv2D(64, kernel_size =(3,3), strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2), strides=2, padding='same')\n",
    "\n",
    "model.add(Conv2D(128, kernel_size =(3,3), strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D(2,2), strides=2, padding='same')\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f6e47",
   "metadata": {},
   "source": [
    "##### when our training dataset is discrete we've to use sparse_categorical_crossentropy as cost funct but when the training dataset is one-hot coded we've to use categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940dd4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c078a",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d32b4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5216/32 #train_set ratio per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f256c605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16/32 #validation_set ratio per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b01f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "624/32 #test_set ratio per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2072ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=163,\n",
    "    batch_size=32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=624,\n",
    "    verbose=1,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d137489",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores #Scores is just a list containing loss and accuracy value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34bb595",
   "metadata": {},
   "source": [
    "#### Plotting the Accuracy and Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0def6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d75734",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ac8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe11b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb7187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdcd8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e5f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344cd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
